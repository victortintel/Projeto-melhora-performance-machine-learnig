ğŸš€ Automated Hyperparameter Tuning for 5 ML Algorithms<br>
Projeto de CriaÃ§Ã£o Automatizada de Modelos Preditivos com Ajuste Fino de HiperparÃ¢metros<br><br>

ğŸ“Œ VisÃ£o Geral<br>
Este repositÃ³rio demonstra como configurar e otimizar hiperparÃ¢metros para cinco algoritmos fundamentais de Machine Learning:<br>

- Random Forest<br>

- SVM (Support Vector Machines)<br>

- KNN (K-Nearest Neighbors)<br>

- Naive Bayes<br>

- RegressÃ£o LogÃ­stica<br><br>

O projeto automatiza a criaÃ§Ã£o e avaliaÃ§Ã£o de mais de 7.000 modelos preditivos, explorando combinaÃ§Ãµes de hiperparÃ¢metros para maximizar performance.
--------------------------------------------
ğŸ” O Que VocÃª Vai Encontrar Aqui:
1. ConfiguraÃ§Ã£o de HiperparÃ¢metros<br>
- Passo a passo para definir grades de parÃ¢metros para cada algoritmo.<br>

- Exemplos prÃ¡ticos de como ajustar:<br>

- n_estimators, max_depth (Random Forest) <br>

- C, kernel (SVM)<br>

- n_neighbors, metric (KNN)<br>

- alpha (Naive Bayes)<br>

- penalty, C (RegressÃ£o LogÃ­stica)<br>

## 2. AutomaÃ§Ã£o de Treinamento
- Uso do GridSearchCV e RandomizedSearchCV para buscar a melhor combinaÃ§Ã£o de parÃ¢metros.

- Processo automatizado que treina milhares de modelos e seleciona o melhor com base em mÃ©tricas (acurÃ¡cia, recall, F1-score).

3. AnÃ¡lise Comparativa
- ComparaÃ§Ã£o de desempenho entre os 5 algoritmos.

- Trade-offs entre acuracia vs. tempo de treinamento.

- DiscussÃ£o sobre interpretabilidade (por que RegressÃ£o LogÃ­stica Ã© mais explicÃ¡vel que Random Forest?).

4. PrÃ©-processamento e AnÃ¡lise ExploratÃ³ria
- Links para vÃ­deos e materiais complementares sobre:

- Tratamento de dados faltantes (missing values).

- AnÃ¡lise de outliers.

- VisualizaÃ§Ãµes (grÃ¡ficos, distribuiÃ§Ãµes).

- NormalizaÃ§Ã£o/PadronizaÃ§Ã£o.

ğŸ› ï¸ Como Usar Este Projeto<br><br>
PrÃ©-requisitos<br>
- Python 3.8+

- Bibliotecas: scikit-learn, pandas, numpy, matplotlib, seaborn

Passos BÃ¡sicos
Clone o repositÃ³rio:

bash
Copy
git clone https://github.com/seu-usuario/hyperparameter-tuning-ml.git
Instale as dependÃªncias:

bash
Copy
pip install -r requirements.txt
Execute o Jupyter Notebook ou script Python:

bash
Copy
jupyter notebook automated_hyperparameter_tuning.ipynb
ğŸ“Š Resultados Destacados
Algoritmo	Melhor AcurÃ¡cia	NÂº de Modelos Testados
Random Forest	78.64%	1080
SVM	75.07%	1536
KNN	74.14%	1144
Naive Bayes	52.79%	12
RegressÃ£o LogÃ­stica	66.5%	2400
ğŸ“Œ Principais Takeaways
âœ” Random Forest teve o melhor desempenho, mas consome mais recursos computacionais.
âœ” SVM e KNN sÃ£o boas alternativas balanceando acurÃ¡cia e eficiÃªncia.
âœ” Naive Bayes foi rÃ¡pido, mas menos preciso â€“ ideal para baseline ou dados pequenos.
âœ” RegressÃ£o LogÃ­stica Ã© mais interpretÃ¡vel, Ãºtil para casos onde explicaÃ§Ã£o Ã© crucial.



# Projeto de Cria√ß√£o Automatizada de Modelos Preditivos com Ajuste Fino de Hiperpar√¢metros<br><br>

## üìå Vis√£o Geral<br>
Este reposit√≥rio demonstra como configurar e otimizar hiperpar√¢metros para cinco algoritmos fundamentais de Machine Learning:<br>

- Random Forest<br>

- SVM (Support Vector Machines)<br>

- KNN (K-Nearest Neighbors)<br>

- Naive Bayes<br>

- Regress√£o Log√≠stica<br><br>

O projeto automatiza a cria√ß√£o e avalia√ß√£o de mais de 7.000 modelos preditivos, explorando combina√ß√µes de hiperpar√¢metros para maximizar performance.
--------------------------------------------
## üîç O Que Voc√™ Vai Encontrar Aqui:
### 1. Configura√ß√£o de Hiperpar√¢metros<br>
- Passo a passo para definir grades de par√¢metros para cada algoritmo.<br>

- Exemplos pr√°ticos de como ajustar:<br>

- n_estimators, max_depth (Random Forest) <br>

- C, kernel (SVM)<br>

- n_neighbors, metric (KNN)<br>

- alpha (Naive Bayes)<br>

- penalty, C (Regress√£o Log√≠stica)<br>

### 2. Automa√ß√£o de Treinamento
- Uso do GridSearchCV e RandomizedSearchCV para buscar a melhor combina√ß√£o de par√¢metros.

- Processo automatizado que treina milhares de modelos e seleciona o melhor com base em m√©tricas (acur√°cia, recall, F1-score).

### 3. An√°lise Comparativa
- Compara√ß√£o de desempenho entre os 5 algoritmos.

- Trade-offs entre acuracia vs. tempo de treinamento.

- Discuss√£o sobre interpretabilidade (por que Regress√£o Log√≠stica √© mais explic√°vel que Random Forest?).

### 4. Pr√©-processamento e An√°lise Explorat√≥ria
- Links para v√≠deos e materiais complementares sobre:

- Tratamento de dados faltantes (missing values).

- An√°lise de outliers.

- Visualiza√ß√µes (gr√°ficos, distribui√ß√µes).

- Normaliza√ß√£o/Padroniza√ß√£o.

## üõ†Ô∏è Como Usar Este Projeto: <br><br>
### Pr√©-requisitos<br>
- Python 3.8+

- Bibliotecas: scikit-learn, pandas, numpy, matplotlib, seaborn

## üìä Resultados Destacados<BR><BR>
Algoritmo	Melhor Acur√°cia	N¬∫ de Modelos Testados:<BR>
- Random Forest	78.64%	1080
- SVM	75.07%	1536
- KNN	74.14%	1144
- Naive Bayes	52.79%	12
- Regress√£o Log√≠stica	66.5%	2400<BR><BR>
## üìå Principais Takeaways: <BR><BR>
- ‚úî Random Forest teve o melhor desempenho, mas consome mais recursos computacionais.
- ‚úî SVM e KNN s√£o boas alternativas balanceando acur√°cia e efici√™ncia.
- ‚úî Naive Bayes foi r√°pido, mas menos preciso ‚Äì ideal para baseline ou dados pequenos.
- ‚úî Regress√£o Log√≠stica √© mais interpret√°vel, √∫til para casos onde explica√ß√£o √© crucial.

